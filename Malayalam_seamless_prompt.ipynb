{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aab168b9-47db-4971-8dca-31972916f320",
   "metadata": {},
   "source": [
    "## Malayalam Speech Keyword generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be9eaf9d-fac9-4e33-8bfc-4984f194aa90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.16.0a0 requires torch==2.1.0a0+4136153, but you have torch 2.1.1 which is incompatible.\n",
      "torchtext 0.16.0a0 requires torch==2.1.0a0+4136153, but you have torch 2.1.1 which is incompatible.\n",
      "torchdata 0.7.0a0 requires torch==2.1.0a0+4136153, but you have torch 2.1.1 which is incompatible.\n",
      "numba 0.56.4+1.g5f1bc7084 requires numpy<1.24,>=1.18, but you have numpy 1.26.3 which is incompatible.\n",
      "cupy-cuda12x 12.0.0b3 requires numpy<1.26,>=1.20, but you have numpy 1.26.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.16.0a0 requires torch==2.1.0a0+4136153, but you have torch 2.1.1 which is incompatible.\n",
      "torchtext 0.16.0a0 requires torch==2.1.0a0+4136153, but you have torch 2.1.1 which is incompatible.\n",
      "torchdata 0.7.0a0 requires torch==2.1.0a0+4136153, but you have torch 2.1.1 which is incompatible.\n",
      "google-auth 2.20.0 requires urllib3<2.0, but you have urllib3 2.1.0 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -Uqq fairseq2\n",
    "!pip install  -Uqq  pydub sentencepiece\n",
    "!pip install  -Uqq git+https://github.com/facebookresearch/seamless_communication.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ce361c8-c1f1-4d75-aa26-93adc78b8163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install -Uqq git+https://github.com/huggingface/transformers.git (4.37.2)\n",
    "! pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3307d48d-7dbe-4ef3-93ff-da2be4e3be2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-ltqocksm\n",
      "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-ltqocksm\n",
      "  Resolved https://github.com/huggingface/transformers to commit 29a2b1420633d322140062d7c76b807f41fb90aa\n",
      "\u001b[33m  WARNING: Value for prefixed-purelib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /tmp/pip-build-env-rr_40ayr/normal/lib/python3.10/site-packages\n",
      "  sysconfig: /tmp/pip-build-env-rr_40ayr/normal/local/lib/python3.10/dist-packages\u001b[0m\n",
      "\u001b[33m  WARNING: Value for prefixed-platlib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /tmp/pip-build-env-rr_40ayr/normal/lib/python3.10/site-packages\n",
      "  sysconfig: /tmp/pip-build-env-rr_40ayr/normal/local/lib/python3.10/dist-packages\u001b[0m\n",
      "\u001b[33m  WARNING: Additional context:\n",
      "  user = False\n",
      "  home = None\n",
      "  root = None\n",
      "  prefix = '/tmp/pip-build-env-rr_40ayr/normal'\u001b[0m\n",
      "\u001b[33m  WARNING: Value for prefixed-purelib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /tmp/pip-build-env-rr_40ayr/overlay/lib/python3.10/site-packages\n",
      "  sysconfig: /tmp/pip-build-env-rr_40ayr/overlay/local/lib/python3.10/dist-packages\u001b[0m\n",
      "\u001b[33m  WARNING: Value for prefixed-platlib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /tmp/pip-build-env-rr_40ayr/overlay/lib/python3.10/site-packages\n",
      "  sysconfig: /tmp/pip-build-env-rr_40ayr/overlay/local/lib/python3.10/dist-packages\u001b[0m\n",
      "\u001b[33m  WARNING: Additional context:\n",
      "  user = False\n",
      "  home = None\n",
      "  root = None\n",
      "  prefix = '/tmp/pip-build-env-rr_40ayr/overlay'\u001b[0m\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.1)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages/bitsandbytes-0.41.1-py3.10.egg (0.41.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (0.15.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (1.23.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (4.64.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (2023.6.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (23.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (0.4.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (0.20.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (6.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (3.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.6.3)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (2.6.3)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0.dev0) (3.1.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0.dev0) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0.dev0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0.dev0) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.37.0.dev0-py3-none-any.whl size=8337212 sha256=8921ad440535bc9370e5d6a5241fccef04f6b2694f96ac9e83635611785fd34f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-1nel7qx2/wheels/c0/14/d6/6c9a5582d2ac191ec0a483be151a4495fe1eb2a6706ca49f1b\n",
      "Successfully built transformers\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.36.2\n",
      "\u001b[33m    WARNING: Value for bin_prefix does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "    distutils: /usr/bin\n",
      "    sysconfig: /usr/local/bin\u001b[0m\n",
      "\u001b[33m    WARNING: Additional context:\n",
      "    user = False\n",
      "    home = None\n",
      "    root = None\n",
      "    prefix = None\u001b[0m\n",
      "    Uninstalling transformers-4.36.2:\n",
      "      Successfully uninstalled transformers-4.36.2\n",
      "Successfully installed transformers-4.37.0.dev0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers torch accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b90fbc97-0f49-4c59-a0e6-d8a0f6e5c1c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "456b6fe5-3272-413c-a971-74e337f868bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "from seamless_communication.inference import Translator\n",
    "from pydub import AudioSegment\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "import wave\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0252ccfe-2bbe-488c-be5f-59c419edbd7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the cached checkpoint of seamlessM4T_v2_large. Set `force` to `True` to download again.\n",
      "Using the cached tokenizer of seamlessM4T_v2_large. Set `force` to `True` to download again.\n",
      "Using the cached tokenizer of seamlessM4T_v2_large. Set `force` to `True` to download again.\n",
      "Using the cached tokenizer of seamlessM4T_v2_large. Set `force` to `True` to download again.\n",
      "Using the cached checkpoint of vocoder_v2. Set `force` to `True` to download again.\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "model_name = \"seamlessM4T_v2_large\"\n",
    "vocoder_name = \"vocoder_v2\" if model_name == \"seamlessM4T_v2_large\" else \"vocoder_36langs\"\n",
    "\n",
    "translator = Translator(\n",
    "    model_name,\n",
    "    vocoder_name,\n",
    "    device=torch.device(\"cuda:0\"),\n",
    "    dtype=torch.float16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74d325bd-0417-41c7-bb06-8e246a7e13f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 192.45 seconds\n",
      "number of samples  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the cached checkpoint of seamlessM4T_v2_large. Set `force` to `True` to download again.\n",
      "Using the cached tokenizer of seamlessM4T_v2_large. Set `force` to `True` to download again.\n",
      "Using the cached tokenizer of seamlessM4T_v2_large. Set `force` to `True` to download again.\n",
      "Using the cached tokenizer of seamlessM4T_v2_large. Set `force` to `True` to download again.\n",
      "Using the cached checkpoint of vocoder_v2. Set `force` to `True` to download again.\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minister P. Rajiv's reaction to the criticism of M.T. Vastevana that there is no authoritarianism in Kerala is in the K.L.F.E.D. The minister criticized that the Centre is weakening the constitutional institutions.\n",
      "I don't think it's a question of whether or not we're going to be able to do it, but I think it's a question of whether or not we're going to be able to do it, and I think it's a question of whether or not we're going to be able to do it, because we're not going to be able to do it.\n",
      "In India, only one state, Kerala, has a parliamentary system that is democratic.\n",
      "This is the first time that such a reply or such a reference has been made by Minister P. Rajiv.\n",
      "In this article, we'll look at the history, culture, and ethics of the MTA, and then we'll take a closer look at the history and culture of the MTA, and then we'll look at the history of the MTA, and then we'll take a closer look at the history and ethics of the MTA.\n",
      "It's been a long time since I've been able to say that I'm a big supporter of the MTA, but I'm not a big supporter of the MTA, and I'm not a big supporter of the MTA, and I'm not a big supporter of the MTA, but I'm a big supporter of the MTA.\n",
      "It's been a long time since I've been in the media, but it's been a long time since I've been in the media, but it's been a long time since I've been in the media, and it's been a long time since I was in the media.\n",
      "It's not a case of a dictatorship, it's not a case of the government of Kerala, it's a case of the central government, it's a case of P.R. Rajiv's side, it's a case of the central government undermining the constitution.\n",
      "In any case, the criticism of the MT is to establish that these criticisms are not against you.\n",
      "(Music playing)\n",
      "Minister P. Rajiv's reaction to the criticism of M.T. Vastevana that there is no authoritarianism in Kerala is in the K.L.F.E.D. The minister criticized that the Centre is weakening the constitutional institutions. I don't think it's a question of whether or not we're going to be able to do it, but I think it's a question of whether or not we're going to be able to do it, and I think it's a question of whether or not we're going to be able to do it, because we're not going to be able to do it. In India, only one state, Kerala, has a parliamentary system that is democratic. This is the first time that such a reply or such a reference has been made by Minister P. Rajiv. In this article, we'll look at the history, culture, and ethics of the MTA, and then we'll take a closer look at the history and culture of the MTA, and then we'll look at the history of the MTA, and then we'll take a closer look at the history and ethics of the MTA. It's been a long time since I've been able to say that I'm a big supporter of the MTA, but I'm not a big supporter of the MTA, and I'm not a big supporter of the MTA, and I'm not a big supporter of the MTA, but I'm a big supporter of the MTA. It's been a long time since I've been in the media, but it's been a long time since I've been in the media, but it's been a long time since I've been in the media, and it's been a long time since I was in the media. It's not a case of a dictatorship, it's not a case of the government of Kerala, it's a case of the central government, it's a case of P.R. Rajiv's side, it's a case of the central government undermining the constitution. In any case, the criticism of the MT is to establish that these criticisms are not against you. (Music playing)\n"
     ]
    }
   ],
   "source": [
    "audio_name = \"audios/sample1.wav\"\n",
    "target_lang = \"eng\"\n",
    "\n",
    "# function to calculate the duration of the input audio clip\n",
    "def get_duration_wave(file_path):\n",
    "   with wave.open(file_path, 'r') as audio_file:\n",
    "      frame_rate = audio_file.getframerate()\n",
    "      n_frames = audio_file.getnframes()\n",
    "      duration = n_frames / float(frame_rate)\n",
    "      return duration\n",
    "\n",
    "\n",
    "duration = get_duration_wave(audio_name)\n",
    "print(f\"Duration: {duration:.2f} seconds\")\n",
    "\n",
    "resample_rate = 16000\n",
    "t1 = 0\n",
    "t2 = 20000\n",
    "\n",
    "# Generating 'n' number of audio samples each with 20seconds duration. This is to avoid issue with the maximum sequence length\n",
    "num_samples = math.ceil(duration/20)\n",
    "print(\"number of samples \", num_samples)\n",
    "\n",
    "# Initializing the translator model\n",
    "model_name = \"seamlessM4T_v2_large\"\n",
    "vocoder_name = \"vocoder_v2\" if model_name == \"seamlessM4T_v2_large\" else \"vocoder_36langs\"\n",
    "\n",
    "translator = Translator(\n",
    "    model_name,\n",
    "    vocoder_name,\n",
    "    device=torch.device(\"cuda:0\"),\n",
    "    dtype=torch.float16,\n",
    ")\n",
    "\n",
    "text = []\n",
    "for i in range(num_samples):\n",
    "    newAudio = AudioSegment.from_wav(audio_name)\n",
    "    newAudio = newAudio[t1:t2]\n",
    "    new_audio_name = \"new_\" + str(t1) + \".wav\"\n",
    "    newAudio.export(new_audio_name, format=\"wav\")\n",
    "    waveform, sample_rate = torchaudio.load(new_audio_name)\n",
    "    resampler = torchaudio.transforms.Resample(sample_rate, resample_rate, dtype=waveform.dtype)\n",
    "    resampled_waveform = resampler(waveform)\n",
    "    torchaudio.save(\"resampled.wav\", resampled_waveform, resample_rate)\n",
    "\n",
    "    translated_text, _ = translator.predict(\"resampled.wav\", \"s2tt\", target_lang)\n",
    "    print(translated_text[0])\n",
    "    text.append(str(translated_text[0]))\n",
    "    t1 = t2\n",
    "    t2 += 20000\n",
    "    os.remove(new_audio_name)\n",
    "os.remove(\"resampled.wav\")\n",
    "\n",
    "print(\" \".join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd4be857-0bf7-46f0-8a4b-20db1556af2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_seamless_response(audio_name, target_lang = \"eng\"):\n",
    "    duration = get_duration_wave(audio_name)\n",
    "    print(f\"Duration: {duration:.2f} seconds\")\n",
    "\n",
    "    resample_rate = 16000\n",
    "    t1 = 0\n",
    "    t2 = 20000\n",
    "\n",
    "    # Generating 'n' number of audio samples each with 20seconds duration. This is to avoid issue with the maximum sequence length\n",
    "    num_samples = math.ceil(duration/20)\n",
    "    print(\"number of samples \", num_samples)\n",
    "\n",
    "    # Initializing the translator model\n",
    "    model_name = \"seamlessM4T_v2_large\"\n",
    "    vocoder_name = \"vocoder_v2\" if model_name == \"seamlessM4T_v2_large\" else \"vocoder_36langs\"\n",
    "\n",
    "    translator = Translator(\n",
    "        model_name,\n",
    "        vocoder_name,\n",
    "        device=torch.device(\"cuda:0\"),\n",
    "        dtype=torch.float16,\n",
    "    )\n",
    "\n",
    "    text = []\n",
    "    for i in range(num_samples):\n",
    "        newAudio = AudioSegment.from_wav(audio_name)\n",
    "        newAudio = newAudio[t1:t2]\n",
    "        new_audio_name = \"new_\" + str(t1) + \".wav\"\n",
    "        newAudio.export(new_audio_name, format=\"wav\")\n",
    "        waveform, sample_rate = torchaudio.load(new_audio_name)\n",
    "        resampler = torchaudio.transforms.Resample(sample_rate, resample_rate, dtype=waveform.dtype)\n",
    "        resampled_waveform = resampler(waveform)\n",
    "        torchaudio.save(\"resampled.wav\", resampled_waveform, resample_rate)\n",
    "\n",
    "        translated_text, _ = translator.predict(\"resampled.wav\", \"s2tt\", target_lang)\n",
    "        print(translated_text[0])\n",
    "        text.append(str(translated_text[0]))\n",
    "        t1 = t2\n",
    "        t2 += 20000\n",
    "        os.remove(new_audio_name)\n",
    "    os.remove(\"resampled.wav\")\n",
    "\n",
    "    return \" \".join(text)\n",
    "\n",
    "def get_duration_wave(file_path):\n",
    "   with wave.open(file_path, 'r') as audio_file:\n",
    "      frame_rate = audio_file.getframerate()\n",
    "      n_frames = audio_file.getnframes()\n",
    "      duration = n_frames / float(frame_rate)\n",
    "      return duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e401127-73a4-4512-8fa1-05522eaa66aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 649.42 seconds\n",
      "number of samples  33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the cached checkpoint of seamlessM4T_v2_large. Set `force` to `True` to download again.\n",
      "Using the cached tokenizer of seamlessM4T_v2_large. Set `force` to `True` to download again.\n",
      "Using the cached tokenizer of seamlessM4T_v2_large. Set `force` to `True` to download again.\n",
      "Using the cached tokenizer of seamlessM4T_v2_large. Set `force` to `True` to download again.\n",
      "Using the cached checkpoint of vocoder_v2. Set `force` to `True` to download again.\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My book is coming out in about a week and people who are interested in that book will read it and they will realize that this paper Malayalam Manorama has manufactured a sentence\n",
      "and put it in quotes in the headline which is not there I think a responsible publication like Malayalam Manorama when it is putting a written manuscript in quotes at least it should be true to what is written my part\n",
      "Never, ever, not a single sentence in that book accuses my party, insulting my party and my work for 55 years.\n",
      "It's not fair for the author to make a headline and put it in court.\n",
      "From 1985 to 1985 when I was in Delhi and I was called Rita because of the emergency and it's about my experience in Delhi in the trade unions in collectively trying to build a women's organization and my\n",
      "and in that the struggle of a woman to establish in that book the struggle of a young woman\n",
      "to establish an independent identity in politics is part of my own experience but nowhere in this book have I ever made the kind of sentence which Malayalam manorama has put in courts\n",
      "It's unfair, it's unethical to put a headline in a book that doesn't exist in the book. I hope they'll give me an apology.\n",
      "No, that's not what I've written in the book. I'd suggest you read my book.\n",
      "And it's the struggle of women in politics and the kind of patriarchal notions that exist in Indian politics.\n",
      "I would advise you to see the book and understand the context in which things are written and I hope it will help young women to understand the importance and the difference of being in a communist party\n",
      "And being in any other party where women aren't respected, so that's the context in which it's written.\n",
      "It's a sensationalist headline, it's not linked to the text at all, and it says things that aren't written.\n",
      "I don't know what's in the text. I haven't read the whole text, but someone told me that this is the headline. It's a manufactured headline and it's not in the text at all.\n",
      "This is a book, it's a public document, people can read the book if they're interested in reading it, and they'll conclude that the headline given by Malayalam Manorama is a completely 100% manufactured headline.\n",
      "I've never read the text of the article, so I'm not commenting on it, I'm just commenting on the headline, and I don't think it's fair.\n",
      "I don't think it's ethical. It's up to Malayalam Manorama to check and see who gave the headline which is not correct.\n",
      "But there's nothing in the party like censorship or who's writing what. Not at all. Our party doesn't function like that at all. And I'm proud to be a member of the CPI-M.\n",
      "I don't know if it's going to help the book or what it's going to do. I think it should be out in a week. No, it's just a publication.\n",
      "It's only 10 years of my life and that's also only about Delhi and my emergency.\n",
      "How Rita and How Rita Learned About Working in a Party in Communist Politics CPM Politburo member Brinda Karat was responding\n",
      "It's a reference to a book that I've never read, and it's a reference to a book that I've never read, and it's a reference to a book that I've never read.\n",
      "In the morning, there was a report that there was a reference in the memoirs of Brinda Karat that independence was not recognized in the party. Now, when it comes to Brinda Karat's reaction, he has not read the whole story, but as the headline says, there was no such experience from the party.\n",
      "It's been said that from the time of the Great Depression to the time of the Great Depression, there were only a handful of books on the subject, and none of them had a title.\n",
      "I'm sure you've all heard the saying, \"Belarus is the most beautiful place on earth,\" but if you've ever heard the phrase, \"Belarus is the most beautiful place on earth,\" then you've probably heard it all before.\n",
      "It's not just that he's portraying his wife as his wife, it's also that he's not mentioning her in any of his books, and he's throwing away the title altogether, and he's publishing something that he doesn't say in his name that's not ethical.\n",
      "I don't know if you're familiar with it, but I've never read it in detail, because it's in Malayalam, so it's just a headline, and a lot of people contacted me after the headline, and a lot of people contacted me.\n",
      "I'm sure you'll agree with me on the title of this post, but I'm not going to go into too much detail about it, so I'll just leave it at that, and then I'll explain what I mean by the title of this post, and then I'll let you know.\n",
      "I'm not sure if it's true, but it's the fact that she's the only woman in the party who hasn't experienced this kind of thing, and it's the fact that she's the only woman in the party who hasn't experienced this kind of thing.\n",
      "It's been a long time since I've had a chance to share with you my 10 years of experience as a writer, and I'd like to share with you some of the things I've learned from my experience as a writer, and I'd like to share with you some of the things I've learned from my experience as a writer.\n",
      "No, it's a party with freedom of speech. It's a party with freedom of speech. It's a party with freedom of speech.\n",
      "Mr. Balram, the information was given by Mr. Balram himself, and he is completely ignoring the news that his independence has not been recognized.\n",
      "I'm not sure if I'm going to be able to do it.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "text2 = generate_seamless_response(\"audios/sample2.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eee24a45-b533-4aa5-a719-50497dc131c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"Minister P. Rajiv's reaction to the criticism of M.T. Vastevana that there is no authoritarianism in Kerala is in the K.L.F.E.D. The minister criticized that the Centre is weakening the constitutional institutions. I don't think it's a question of whether or not we're going to be able to do it, but I think it's a question of whether or not we're going to be able to do it, and I think it's a question of whether or not we're going to be able to do it, because we're not going to be able to do it. In India, only one state, Kerala, has a parliamentary system that is democratic. This is the first time that such a reply or such a reference has been made by Minister P. Rajiv. In this article, we'll look at the history, culture, and ethics of the MTA, and then we'll take a closer look at the history and culture of the MTA, and then we'll look at the history of the MTA, and then we'll take a closer look at the history and ethics of the MTA. It's been a long time since I've been able to say that I'm a big supporter of the MTA, but I'm not a big supporter of the MTA, and I'm not a big supporter of the MTA, and I'm not a big supporter of the MTA, but I'm a big supporter of the MTA. It's been a long time since I've been in the media, but it's been a long time since I've been in the media, but it's been a long time since I've been in the media, and it's been a long time since I was in the media. It's not a case of a dictatorship, it's not a case of the government of Kerala, it's a case of the central government, it's a case of P.R. Rajiv's side, it's a case of the central government undermining the constitution. In any case, the criticism of the MT is to establish that these criticisms are not against you. (Music playing)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "775dd8af-e33d-4311-8f4b-eb6fe1f93be6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoModelForCausalLM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# the device to load the model onto\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistralai/Mistral-7B-Instruct-v0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistralai/Mistral-7B-Instruct-v0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AutoModelForCausalLM' is not defined"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c535ac6-df5f-44c3-8341-c0098810401e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.mistral.modeling_mistral because of the following error (look up to see its traceback):\nFailed to import transformers.generation.utils because of the following error (look up to see its traceback):\n/usr/local/lib/python3.10/dist-packages/transformer_engine_extensions.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py:1364\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1363\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1365\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:92\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_accelerate_available():\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maccelerate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AlignDevicesHook, add_hook_to_module\n\u001b[1;32m     95\u001b[0m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGreedySearchDecoderOnlyOutput\u001b[39;00m(ModelOutput):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.23.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maccelerator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Accelerator\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbig_modeling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     cpu_offload,\n\u001b[1;32m      6\u001b[0m     cpu_offload_with_hook,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     load_checkpoint_and_dispatch,\n\u001b[1;32m     12\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhooks\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpointing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoaderDispatcher, prepare_data_loader, skip_first_batches\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/checkpointing.py:24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mamp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradScaler\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     25\u001b[0m     MODEL_NAME,\n\u001b[1;32m     26\u001b[0m     OPTIMIZER_NAME,\n\u001b[1;32m     27\u001b[0m     RNG_STATE_NAME,\n\u001b[1;32m     28\u001b[0m     SCALER_NAME,\n\u001b[1;32m     29\u001b[0m     SCHEDULER_NAME,\n\u001b[1;32m     30\u001b[0m     get_pretty_name,\n\u001b[1;32m     31\u001b[0m     is_tpu_available,\n\u001b[1;32m     32\u001b[0m     is_xpu_available,\n\u001b[1;32m     33\u001b[0m     save,\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_tpu_available(check_device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/__init__.py:138\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfsdp_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_fsdp_model, load_fsdp_optimizer, save_fsdp_model, save_fsdp_optimizer\n\u001b[0;32m--> 138\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlaunch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    139\u001b[0m     PrepareForLaunch,\n\u001b[1;32m    140\u001b[0m     _filter_args,\n\u001b[1;32m    141\u001b[0m     prepare_deepspeed_cmd_env,\n\u001b[1;32m    142\u001b[0m     prepare_multi_gpu_env,\n\u001b[1;32m    143\u001b[0m     prepare_sagemager_args_inputs,\n\u001b[1;32m    144\u001b[0m     prepare_simple_launcher_cmd_env,\n\u001b[1;32m    145\u001b[0m     prepare_tpu,\n\u001b[1;32m    146\u001b[0m )\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmegatron_lm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    148\u001b[0m     AbstractTrainStep,\n\u001b[1;32m    149\u001b[0m     BertTrainStep,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    158\u001b[0m     gather_across_data_parallel_groups,\n\u001b[1;32m    159\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/launch.py:33\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DEEPSPEED_MULTINODE_LAUNCHERS\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mother\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_port_in_use, merge_dicts\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataclasses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistributedType, SageMakerDistributedType\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/other.py:27\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimports\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_deepspeed_available, is_safetensors_available, is_tpu_available\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformer_engine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_model\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_torch_version\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/transformer_engine.py:21\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_fp8_available():\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransformer_engine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mte\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_model\u001b[39m(model, to_transformer_engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, _convert_linear\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, _convert_ln\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_engine/pytorch/__init__.py:6\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"Transformer Engine bindings for pyTorch\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LayerNormLinear\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Linear\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_engine/pytorch/module/__init__.py:6\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"Module level PyTorch APIs\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayernorm_linear\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LayerNormLinear\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Linear\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_engine/pytorch/module/layernorm_linear.py:14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m init\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransformer_engine_extensions\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtex\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     17\u001b[0m     get_workspace,\n\u001b[1;32m     18\u001b[0m     _prepare_backward,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     _2X_ACC_WGRAD,\n\u001b[1;32m     24\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: /usr/local/lib/python3.10/dist-packages/transformer_engine_extensions.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py:1364\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1363\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1365\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mistral/modeling_mistral.py:36\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_outputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModelOutputWithPast, CausalLMOutputWithPast, SequenceClassifierOutputWithPast\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     38\u001b[0m     add_start_docstrings,\n\u001b[1;32m     39\u001b[0m     add_start_docstrings_to_model_forward,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m     replace_return_docstrings,\n\u001b[1;32m     44\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:44\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic_module_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m custom_object_save\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GenerationConfig, GenerationMixin\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeftAdapterMixin, deepspeed_config, is_deepspeed_zero3_enabled\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1075\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py:1354\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1354\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1355\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py:1366\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1365\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1366\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1367\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1368\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1369\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.generation.utils because of the following error (look up to see its traceback):\n/usr/local/lib/python3.10/dist-packages/transformer_engine_extensions.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer\n\u001b[1;32m      3\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# the device to load the model onto\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmistralai/Mistral-7B-Instruct-v0.1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistralai/Mistral-7B-Instruct-v0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:565\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    562\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    563\u001b[0m     )\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m--> 565\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m \u001b[43m_get_model_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_mapping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    567\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    568\u001b[0m     )\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    572\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:387\u001b[0m, in \u001b[0;36m_get_model_class\u001b[0;34m(config, model_mapping)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_model_class\u001b[39m(config, model_mapping):\n\u001b[0;32m--> 387\u001b[0m     supported_models \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(supported_models, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m supported_models\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:740\u001b[0m, in \u001b[0;36m_LazyAutoMapping.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping:\n\u001b[1;32m    739\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping[model_type]\n\u001b[0;32m--> 740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_attr_from_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;66;03m# Maybe there was several model types associated with this config.\u001b[39;00m\n\u001b[1;32m    743\u001b[0m model_types \u001b[38;5;241m=\u001b[39m [k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config_mapping\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;241m==\u001b[39m key\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:754\u001b[0m, in \u001b[0;36m_LazyAutoMapping._load_attr_from_module\u001b[0;34m(self, model_type, attr)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n\u001b[1;32m    753\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules[module_name] \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformers.models\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 754\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetattribute_from_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_modules\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:698\u001b[0m, in \u001b[0;36mgetattribute_from_module\u001b[0;34m(module, attr)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(attr, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(getattribute_from_module(module, a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m attr)\n\u001b[0;32m--> 698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, attr)\n\u001b[1;32m    700\u001b[0m \u001b[38;5;66;03m# Some of the mappings have entries model_type -> object of another model type. In that case we try to grab the\u001b[39;00m\n\u001b[1;32m    701\u001b[0m \u001b[38;5;66;03m# object at the top level.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py:1354\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1352\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1354\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1355\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py:1366\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1365\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1366\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1367\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1368\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1369\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.models.mistral.modeling_mistral because of the following error (look up to see its traceback):\nFailed to import transformers.generation.utils because of the following error (look up to see its traceback):\n/usr/local/lib/python3.10/dist-packages/transformer_engine_extensions.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7d80a7-e310-44ba-9893-4a3f1d0a8a16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"User I am giving you the title and short description of the news article in the format [Title:Description]. Give me relevant keywords like News, sports, entertainment,wellness or the related high level topics like important persons, political party, type of sports, etc. Please generate atleast five keyword's for the article \\n {text}\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e262ae4d-33dc-4cda-9603-d79bf6da2b4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "\n",
    "model_inputs = encodeds.to(device)\n",
    "model.to(device)\n",
    "\n",
    "generated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True)\n",
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "print(decoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49cca85c-295a-4321-b0cf-d1e06966db83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Minister P. Rajiv's reaction to the criticism of M.T. Vastevana that there is no authoritarianism in Kerala is in the K.L.F.E.D. The minister criticized that the Centre is weakening the constitutional institutions. I don't think it's a question of whether or not we're going to be able to do it, but I think it's a question of whether or not we're going to be able to do it, and I think it's a question of whether or not we're going to be able to do it, because we're not going to be able to do it. In India, only one state, Kerala, has a parliamentary system that is democratic. This is the first time that such a reply or such a reference has been made by Minister P. Rajiv. In this article, we'll look at the history, culture, and ethics of the MTA, and then we'll take a closer look at the history and culture of the MTA, and then we'll look at the history of the MTA, and then we'll take a closer look at the history and ethics of the MTA. It's been a long time since I've been able to say that I'm a big supporter of the MTA, but I'm not a big supporter of the MTA, and I'm not a big supporter of the MTA, and I'm not a big supporter of the MTA, but I'm a big supporter of the MTA. It's been a long time since I've been in the media, but it's been a long time since I've been in the media, but it's been a long time since I've been in the media, and it's been a long time since I was in the media. It's not a case of a dictatorship, it's not a case of the government of Kerala, it's a case of the central government, it's a case of P.R. Rajiv's side, it's a case of the central government undermining the constitution. In any case, the criticism of the MT is to establish that these criticisms are not against you. (Music playing)\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0111bfea-ad2c-4381-a827-d994c536d8bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "Keywords: Minister P. Rajiv, Kerala, Constitutional Institutions, Central Government, Democracy, M.T. Vastevana, Politics, India. Additional keywords could include: Parliamentary System, Ethics, Culture, History, Constitution, Undermine, Criticism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17bf601e-e753-4b2a-85f2-7b30a558494a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My book is coming out in about a week and people who are interested in that book will read it and they will realize that this paper Malayalam Manorama has manufactured a sentence and put it in quotes in the headline which is not there I think a responsible publication like Malayalam Manorama when it is putting a written manuscript in quotes at least it should be true to what is written my part Never, ever, not a single sentence in that book accuses my party, insulting my party and my work for 55 years. It\\'s not fair for the author to make a headline and put it in court. From 1985 to 1985 when I was in Delhi and I was called Rita because of the emergency and it\\'s about my experience in Delhi in the trade unions in collectively trying to build a women\\'s organization and my and in that the struggle of a woman to establish in that book the struggle of a young woman to establish an independent identity in politics is part of my own experience but nowhere in this book have I ever made the kind of sentence which Malayalam manorama has put in courts It\\'s unfair, it\\'s unethical to put a headline in a book that doesn\\'t exist in the book. I hope they\\'ll give me an apology. No, that\\'s not what I\\'ve written in the book. I\\'d suggest you read my book. And it\\'s the struggle of women in politics and the kind of patriarchal notions that exist in Indian politics. I would advise you to see the book and understand the context in which things are written and I hope it will help young women to understand the importance and the difference of being in a communist party And being in any other party where women aren\\'t respected, so that\\'s the context in which it\\'s written. It\\'s a sensationalist headline, it\\'s not linked to the text at all, and it says things that aren\\'t written. I don\\'t know what\\'s in the text. I haven\\'t read the whole text, but someone told me that this is the headline. It\\'s a manufactured headline and it\\'s not in the text at all. This is a book, it\\'s a public document, people can read the book if they\\'re interested in reading it, and they\\'ll conclude that the headline given by Malayalam Manorama is a completely 100% manufactured headline. I\\'ve never read the text of the article, so I\\'m not commenting on it, I\\'m just commenting on the headline, and I don\\'t think it\\'s fair. I don\\'t think it\\'s ethical. It\\'s up to Malayalam Manorama to check and see who gave the headline which is not correct. But there\\'s nothing in the party like censorship or who\\'s writing what. Not at all. Our party doesn\\'t function like that at all. And I\\'m proud to be a member of the CPI-M. I don\\'t know if it\\'s going to help the book or what it\\'s going to do. I think it should be out in a week. No, it\\'s just a publication. It\\'s only 10 years of my life and that\\'s also only about Delhi and my emergency. How Rita and How Rita Learned About Working in a Party in Communist Politics CPM Politburo member Brinda Karat was responding It\\'s a reference to a book that I\\'ve never read, and it\\'s a reference to a book that I\\'ve never read, and it\\'s a reference to a book that I\\'ve never read. In the morning, there was a report that there was a reference in the memoirs of Brinda Karat that independence was not recognized in the party. Now, when it comes to Brinda Karat\\'s reaction, he has not read the whole story, but as the headline says, there was no such experience from the party. It\\'s been said that from the time of the Great Depression to the time of the Great Depression, there were only a handful of books on the subject, and none of them had a title. I\\'m sure you\\'ve all heard the saying, \"Belarus is the most beautiful place on earth,\" but if you\\'ve ever heard the phrase, \"Belarus is the most beautiful place on earth,\" then you\\'ve probably heard it all before. It\\'s not just that he\\'s portraying his wife as his wife, it\\'s also that he\\'s not mentioning her in any of his books, and he\\'s throwing away the title altogether, and he\\'s publishing something that he doesn\\'t say in his name that\\'s not ethical. I don\\'t know if you\\'re familiar with it, but I\\'ve never read it in detail, because it\\'s in Malayalam, so it\\'s just a headline, and a lot of people contacted me after the headline, and a lot of people contacted me. I\\'m sure you\\'ll agree with me on the title of this post, but I\\'m not going to go into too much detail about it, so I\\'ll just leave it at that, and then I\\'ll explain what I mean by the title of this post, and then I\\'ll let you know. I\\'m not sure if it\\'s true, but it\\'s the fact that she\\'s the only woman in the party who hasn\\'t experienced this kind of thing, and it\\'s the fact that she\\'s the only woman in the party who hasn\\'t experienced this kind of thing. It\\'s been a long time since I\\'ve had a chance to share with you my 10 years of experience as a writer, and I\\'d like to share with you some of the things I\\'ve learned from my experience as a writer, and I\\'d like to share with you some of the things I\\'ve learned from my experience as a writer. No, it\\'s a party with freedom of speech. It\\'s a party with freedom of speech. It\\'s a party with freedom of speech. Mr. Balram, the information was given by Mr. Balram himself, and he is completely ignoring the news that his independence has not been recognized. I\\'m not sure if I\\'m going to be able to do it.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c64c67c-aed1-446e-b66a-43e95e0b3ac6",
   "metadata": {},
   "source": [
    "Keywords: Brinda Karat, Book, Headline, Malayalam Manorama, Politics, Communists, CPI-M, Memoir, Freedom of Speech, Experience, Independence, Party, Journalism, Ethics. Additional keywords could include: Misrepresentation, Accuracy, Responsibility, Public Document, Context, Young Women, Patriarchy, Indian Politics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8216f109-7b77-4a3a-8f43-c825331b8e5c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4330ba59-6c99-4f06-9a0a-e8d8ba9cb232",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
